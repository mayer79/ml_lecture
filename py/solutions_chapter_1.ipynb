{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Basics and Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chapter 1 exercise imports and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, GammaRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "diamonds = pd.read_parquet(\"diamonds.parquet\")  # Or sns.load_dataset(\"diamonds\")\n",
    "\n",
    "ord_vars = [\"color\", \"cut\", \"clarity\"]\n",
    "ord_levels = [diamonds[x].cat.categories.to_list() for x in ord_vars]\n",
    "\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise on linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1156.648\n",
      "R-squared: 91.59%\n",
      "Intercept -944.9008751128845\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carat</th>\n",
       "      <td>8886.128884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_E</th>\n",
       "      <td>-211.682482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_F</th>\n",
       "      <td>-303.310033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_G</th>\n",
       "      <td>-506.199536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_H</th>\n",
       "      <td>-978.697664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_I</th>\n",
       "      <td>-1440.301902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_J</th>\n",
       "      <td>-2325.222360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Premium</th>\n",
       "      <td>-128.858534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Very Good</th>\n",
       "      <td>-149.537561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Good</th>\n",
       "      <td>-342.486990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Fair</th>\n",
       "      <td>-998.254438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <td>-347.619200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <td>-452.447435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VS1</th>\n",
       "      <td>-884.767875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VS2</th>\n",
       "      <td>-1201.817743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_SI1</th>\n",
       "      <td>-1845.958857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_SI2</th>\n",
       "      <td>-2793.696857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_I1</th>\n",
       "      <td>-5419.646845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Estimates\n",
       "carat          8886.128884\n",
       "color_E        -211.682482\n",
       "color_F        -303.310033\n",
       "color_G        -506.199536\n",
       "color_H        -978.697664\n",
       "color_I       -1440.301902\n",
       "color_J       -2325.222360\n",
       "cut_Premium    -128.858534\n",
       "cut_Very Good  -149.537561\n",
       "cut_Good       -342.486990\n",
       "cut_Fair       -998.254438\n",
       "clarity_VVS1   -347.619200\n",
       "clarity_VVS2   -452.447435\n",
       "clarity_VS1    -884.767875\n",
       "clarity_VS2   -1201.817743\n",
       "clarity_SI1   -1845.958857\n",
       "clarity_SI2   -2793.696857\n",
       "clarity_I1    -5419.646845"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Via scikit-learn\n",
    "y = diamonds[\"price\"]\n",
    "\n",
    "model = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"linear\", \"passthrough\", [\"carat\"]),\n",
    "            (\"dummies\", OneHotEncoder(categories=ord_levels, drop=\"first\"), ord_vars),\n",
    "        ],\n",
    "        verbose_feature_names_out=False,\n",
    "    ),\n",
    "    LinearRegression(),\n",
    ")\n",
    "model.fit(diamonds, y)\n",
    "\n",
    "rmse = root_mean_squared_error(y, model.predict(diamonds))\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"R-squared: {model.score(diamonds, y):.2%}\")\n",
    "print(\"Intercept\", model[-1].intercept_)\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    model[-1].coef_, columns=[\"Estimates\"], index=model[:-1].get_feature_names_out()\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.916</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.916</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>3.264e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 16 Feb 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:11:28</td>     <th>  Log-Likelihood:    </th> <td>-4.5699e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 53940</td>      <th>  AIC:               </th>  <td>9.140e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 53921</td>      <th>  BIC:               </th>  <td>9.142e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    18</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td> -944.9009</td> <td>   31.395</td> <td>  -30.098</td> <td> 0.000</td> <td>-1006.434</td> <td> -883.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color[T.E]</th>       <td> -211.6825</td> <td>   18.316</td> <td>  -11.557</td> <td> 0.000</td> <td> -247.582</td> <td> -175.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color[T.F]</th>       <td> -303.3100</td> <td>   18.509</td> <td>  -16.387</td> <td> 0.000</td> <td> -339.589</td> <td> -267.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color[T.G]</th>       <td> -506.1995</td> <td>   18.122</td> <td>  -27.933</td> <td> 0.000</td> <td> -541.719</td> <td> -470.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color[T.H]</th>       <td> -978.6977</td> <td>   19.272</td> <td>  -50.784</td> <td> 0.000</td> <td>-1016.471</td> <td> -940.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color[T.I]</th>       <td>-1440.3019</td> <td>   21.646</td> <td>  -66.538</td> <td> 0.000</td> <td>-1482.729</td> <td>-1397.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>color[T.J]</th>       <td>-2325.2224</td> <td>   26.723</td> <td>  -87.013</td> <td> 0.000</td> <td>-2377.599</td> <td>-2272.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cut[T.Premium]</th>   <td> -128.8585</td> <td>   12.894</td> <td>   -9.994</td> <td> 0.000</td> <td> -154.131</td> <td> -103.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cut[T.Very Good]</th> <td> -149.5376</td> <td>   13.265</td> <td>  -11.273</td> <td> 0.000</td> <td> -175.538</td> <td> -123.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cut[T.Good]</th>      <td> -342.4870</td> <td>   18.524</td> <td>  -18.489</td> <td> 0.000</td> <td> -378.794</td> <td> -306.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cut[T.Fair]</th>      <td> -998.2544</td> <td>   30.656</td> <td>  -32.563</td> <td> 0.000</td> <td>-1058.341</td> <td> -938.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity[T.VVS1]</th>  <td> -347.6192</td> <td>   33.440</td> <td>  -10.395</td> <td> 0.000</td> <td> -413.162</td> <td> -282.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity[T.VVS2]</th>  <td> -452.4474</td> <td>   31.951</td> <td>  -14.160</td> <td> 0.000</td> <td> -515.072</td> <td> -389.822</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity[T.VS1]</th>   <td> -884.7679</td> <td>   30.456</td> <td>  -29.050</td> <td> 0.000</td> <td> -944.463</td> <td> -825.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity[T.VS2]</th>   <td>-1201.8177</td> <td>   29.721</td> <td>  -40.436</td> <td> 0.000</td> <td>-1260.072</td> <td>-1143.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity[T.SI1]</th>   <td>-1845.9589</td> <td>   29.857</td> <td>  -61.827</td> <td> 0.000</td> <td>-1904.479</td> <td>-1787.439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity[T.SI2]</th>   <td>-2793.6969</td> <td>   31.085</td> <td>  -89.873</td> <td> 0.000</td> <td>-2854.624</td> <td>-2732.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clarity[T.I1]</th>    <td>-5419.6468</td> <td>   52.136</td> <td> -103.952</td> <td> 0.000</td> <td>-5521.834</td> <td>-5317.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>carat</th>            <td> 8886.1289</td> <td>   12.034</td> <td>  738.437</td> <td> 0.000</td> <td> 8862.543</td> <td> 8909.715</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15285.474</td> <th>  Durbin-Watson:     </th>  <td>   0.907</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>183262.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.022</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>11.796</td>   <th>  Cond. No.          </th>  <td>    24.2</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &      0.916   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.916   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &  3.264e+04   \\\\\n",
       "\\textbf{Date:}             & Fri, 16 Feb 2024 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}             &     18:11:28     & \\textbf{  Log-Likelihood:    } & -4.5699e+05  \\\\\n",
       "\\textbf{No. Observations:} &       53940      & \\textbf{  AIC:               } &  9.140e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &       53921      & \\textbf{  BIC:               } &  9.142e+05   \\\\\n",
       "\\textbf{Df Model:}         &          18      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}        &    -944.9009  &       31.395     &   -30.098  &         0.000        &    -1006.434    &     -883.367     \\\\\n",
       "\\textbf{color[T.E]}       &    -211.6825  &       18.316     &   -11.557  &         0.000        &     -247.582    &     -175.783     \\\\\n",
       "\\textbf{color[T.F]}       &    -303.3100  &       18.509     &   -16.387  &         0.000        &     -339.589    &     -267.031     \\\\\n",
       "\\textbf{color[T.G]}       &    -506.1995  &       18.122     &   -27.933  &         0.000        &     -541.719    &     -470.680     \\\\\n",
       "\\textbf{color[T.H]}       &    -978.6977  &       19.272     &   -50.784  &         0.000        &    -1016.471    &     -940.925     \\\\\n",
       "\\textbf{color[T.I]}       &   -1440.3019  &       21.646     &   -66.538  &         0.000        &    -1482.729    &    -1397.875     \\\\\n",
       "\\textbf{color[T.J]}       &   -2325.2224  &       26.723     &   -87.013  &         0.000        &    -2377.599    &    -2272.846     \\\\\n",
       "\\textbf{cut[T.Premium]}   &    -128.8585  &       12.894     &    -9.994  &         0.000        &     -154.131    &     -103.586     \\\\\n",
       "\\textbf{cut[T.Very Good]} &    -149.5376  &       13.265     &   -11.273  &         0.000        &     -175.538    &     -123.537     \\\\\n",
       "\\textbf{cut[T.Good]}      &    -342.4870  &       18.524     &   -18.489  &         0.000        &     -378.794    &     -306.180     \\\\\n",
       "\\textbf{cut[T.Fair]}      &    -998.2544  &       30.656     &   -32.563  &         0.000        &    -1058.341    &     -938.168     \\\\\n",
       "\\textbf{clarity[T.VVS1]}  &    -347.6192  &       33.440     &   -10.395  &         0.000        &     -413.162    &     -282.076     \\\\\n",
       "\\textbf{clarity[T.VVS2]}  &    -452.4474  &       31.951     &   -14.160  &         0.000        &     -515.072    &     -389.822     \\\\\n",
       "\\textbf{clarity[T.VS1]}   &    -884.7679  &       30.456     &   -29.050  &         0.000        &     -944.463    &     -825.073     \\\\\n",
       "\\textbf{clarity[T.VS2]}   &   -1201.8177  &       29.721     &   -40.436  &         0.000        &    -1260.072    &    -1143.564     \\\\\n",
       "\\textbf{clarity[T.SI1]}   &   -1845.9589  &       29.857     &   -61.827  &         0.000        &    -1904.479    &    -1787.439     \\\\\n",
       "\\textbf{clarity[T.SI2]}   &   -2793.6969  &       31.085     &   -89.873  &         0.000        &    -2854.624    &    -2732.770     \\\\\n",
       "\\textbf{clarity[T.I1]}    &   -5419.6468  &       52.136     &  -103.952  &         0.000        &    -5521.834    &    -5317.460     \\\\\n",
       "\\textbf{carat}            &    8886.1289  &       12.034     &   738.437  &         0.000        &     8862.543    &     8909.715     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 15285.474 & \\textbf{  Durbin-Watson:     } &     0.907   \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 183262.957  \\\\\n",
       "\\textbf{Skew:}          &    1.022  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      &   11.796  & \\textbf{  Cond. No.          } &      24.2   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.916\n",
       "Model:                            OLS   Adj. R-squared:                  0.916\n",
       "Method:                 Least Squares   F-statistic:                 3.264e+04\n",
       "Date:                Fri, 16 Feb 2024   Prob (F-statistic):               0.00\n",
       "Time:                        18:11:28   Log-Likelihood:            -4.5699e+05\n",
       "No. Observations:               53940   AIC:                         9.140e+05\n",
       "Df Residuals:                   53921   BIC:                         9.142e+05\n",
       "Df Model:                          18                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept         -944.9009     31.395    -30.098      0.000   -1006.434    -883.367\n",
       "color[T.E]        -211.6825     18.316    -11.557      0.000    -247.582    -175.783\n",
       "color[T.F]        -303.3100     18.509    -16.387      0.000    -339.589    -267.031\n",
       "color[T.G]        -506.1995     18.122    -27.933      0.000    -541.719    -470.680\n",
       "color[T.H]        -978.6977     19.272    -50.784      0.000   -1016.471    -940.925\n",
       "color[T.I]       -1440.3019     21.646    -66.538      0.000   -1482.729   -1397.875\n",
       "color[T.J]       -2325.2224     26.723    -87.013      0.000   -2377.599   -2272.846\n",
       "cut[T.Premium]    -128.8585     12.894     -9.994      0.000    -154.131    -103.586\n",
       "cut[T.Very Good]  -149.5376     13.265    -11.273      0.000    -175.538    -123.537\n",
       "cut[T.Good]       -342.4870     18.524    -18.489      0.000    -378.794    -306.180\n",
       "cut[T.Fair]       -998.2544     30.656    -32.563      0.000   -1058.341    -938.168\n",
       "clarity[T.VVS1]   -347.6192     33.440    -10.395      0.000    -413.162    -282.076\n",
       "clarity[T.VVS2]   -452.4474     31.951    -14.160      0.000    -515.072    -389.822\n",
       "clarity[T.VS1]    -884.7679     30.456    -29.050      0.000    -944.463    -825.073\n",
       "clarity[T.VS2]   -1201.8177     29.721    -40.436      0.000   -1260.072   -1143.564\n",
       "clarity[T.SI1]   -1845.9589     29.857    -61.827      0.000   -1904.479   -1787.439\n",
       "clarity[T.SI2]   -2793.6969     31.085    -89.873      0.000   -2854.624   -2732.770\n",
       "clarity[T.I1]    -5419.6468     52.136   -103.952      0.000   -5521.834   -5317.460\n",
       "carat             8886.1289     12.034    738.437      0.000    8862.543    8909.715\n",
       "==============================================================================\n",
       "Omnibus:                    15285.474   Durbin-Watson:                   0.907\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           183262.957\n",
       "Skew:                           1.022   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.796   Cond. No.                         24.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Via statsmodels\n",
    "model2 = smf.ols(\"price ~ carat + color + cut + clarity\", data=diamonds).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1156.648\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE: {root_mean_squared_error(y, model2.predict(diamonds)):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "\n",
    "- **Model quality:** About 92% of price variations are explained by covariates. Typical prediction error is 1157 USD.\n",
    "- **Effects:** All effects point into the intuitively right direction (larger stones are more expensive, worse color are less expensive etc.)\n",
    "- **Practical perspective:** Additivity in color, cut and clarity are not making sense. Their effects should get larger with larger diamond size. This can be solved by adding interaction terms with carat or, much easier, to switch to a logarithmic response.\n",
    "\n",
    "## Exercise on GLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   No. Observations:                53940\n",
      "Model:                            GLM   Df Residuals:                    53921\n",
      "Model Family:                   Gamma   Df Model:                           18\n",
      "Link Function:                    Log   Scale:                        0.019471\n",
      "Method:                          IRLS   Log-Likelihood:            -3.8857e+05\n",
      "Date:                Fri, 16 Feb 2024   Deviance:                       978.68\n",
      "Time:                        18:11:29   Pearson chi2:                 1.05e+03\n",
      "No. Iterations:                    12   Pseudo R-squ. (CS):              1.000\n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            9.1446      0.004   2304.872      0.000       9.137       9.152\n",
      "color[T.E]          -0.0563      0.002    -25.481      0.000      -0.061      -0.052\n",
      "color[T.F]          -0.0964      0.002    -43.137      0.000      -0.101      -0.092\n",
      "color[T.G]          -0.1635      0.002    -74.787      0.000      -0.168      -0.159\n",
      "color[T.H]          -0.2535      0.002   -109.255      0.000      -0.258      -0.249\n",
      "color[T.I]          -0.3743      0.003   -144.011      0.000      -0.379      -0.369\n",
      "color[T.J]          -0.5111      0.003   -159.433      0.000      -0.517      -0.505\n",
      "cut[T.Premium]      -0.0207      0.002    -13.348      0.000      -0.024      -0.018\n",
      "cut[T.Very Good]    -0.0449      0.002    -28.055      0.000      -0.048      -0.042\n",
      "cut[T.Good]         -0.0815      0.002    -36.456      0.000      -0.086      -0.077\n",
      "cut[T.Fair]         -0.1532      0.004    -41.398      0.000      -0.160      -0.146\n",
      "clarity[T.VVS1]     -0.0965      0.004    -23.916      0.000      -0.104      -0.089\n",
      "clarity[T.VVS2]     -0.1674      0.004    -43.423      0.000      -0.175      -0.160\n",
      "clarity[T.VS1]      -0.3058      0.004    -83.074      0.000      -0.313      -0.299\n",
      "clarity[T.VS2]      -0.3754      0.004   -104.431      0.000      -0.382      -0.368\n",
      "clarity[T.SI1]      -0.5254      0.004   -145.225      0.000      -0.533      -0.518\n",
      "clarity[T.SI2]      -0.6879      0.004   -182.564      0.000      -0.695      -0.681\n",
      "clarity[T.I1]       -1.0982      0.006   -174.625      0.000      -1.110      -1.086\n",
      "np.log(carat)        1.8816      0.001   1598.304      0.000       1.879       1.884\n",
      "====================================================================================\n",
      "Relative bias on USD scale: 0.336%\n"
     ]
    }
   ],
   "source": [
    "# Via statsmodels\n",
    "model = smf.glm(\n",
    "    \"price ~ np.log(carat) + color + cut + clarity\",\n",
    "    data=diamonds,\n",
    "    family=sm.families.Gamma(sm.families.links.Log()),\n",
    ").fit()\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "bias = diamonds[\"price\"].mean() / model.predict(diamonds).mean() - 1\n",
    "print(f\"Relative bias on USD scale: {bias:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ml_lecture\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"d:\\ml_lecture\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent deviance explained: 98.15%\n",
      "Relative bias on USD scale: 0.336%\n",
      "Intercept 9.144584407895891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carat</th>\n",
       "      <td>1.881556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_E</th>\n",
       "      <td>-0.056294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_F</th>\n",
       "      <td>-0.096366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_G</th>\n",
       "      <td>-0.163527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_H</th>\n",
       "      <td>-0.253498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_I</th>\n",
       "      <td>-0.374275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color_J</th>\n",
       "      <td>-0.511088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Premium</th>\n",
       "      <td>-0.020745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Very Good</th>\n",
       "      <td>-0.044901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Good</th>\n",
       "      <td>-0.081495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut_Fair</th>\n",
       "      <td>-0.153177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <td>-0.096467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <td>-0.167420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VS1</th>\n",
       "      <td>-0.305798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_VS2</th>\n",
       "      <td>-0.375376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_SI1</th>\n",
       "      <td>-0.525412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_SI2</th>\n",
       "      <td>-0.687907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity_I1</th>\n",
       "      <td>-1.098154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Estimates\n",
       "carat           1.881556\n",
       "color_E        -0.056294\n",
       "color_F        -0.096366\n",
       "color_G        -0.163527\n",
       "color_H        -0.253498\n",
       "color_I        -0.374275\n",
       "color_J        -0.511088\n",
       "cut_Premium    -0.020745\n",
       "cut_Very Good  -0.044901\n",
       "cut_Good       -0.081495\n",
       "cut_Fair       -0.153177\n",
       "clarity_VVS1   -0.096467\n",
       "clarity_VVS2   -0.167420\n",
       "clarity_VS1    -0.305798\n",
       "clarity_VS2    -0.375376\n",
       "clarity_SI1    -0.525412\n",
       "clarity_SI2    -0.687907\n",
       "clarity_I1     -1.098154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Via scikit-learn\n",
    "y = diamonds[\"price\"]\n",
    "\n",
    "# Define log_carat outside pipeline as it is tricky to track feature names\n",
    "diamonds[\"log_carat\"] = np.log(diamonds[\"carat\"])\n",
    "\n",
    "# Define and fit model pipeline. Note: GammaRegressor directly uses log-link\n",
    "take_log = FunctionTransformer(np.log, feature_names_out=\"one-to-one\")\n",
    "model2 = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"log_carat\", take_log, [\"carat\"]),\n",
    "            (\"dummies\", OneHotEncoder(categories=ord_levels, drop=\"first\"), ord_vars),\n",
    "        ],\n",
    "        verbose_feature_names_out=False,\n",
    "    ),\n",
    "    GammaRegressor(alpha=0, solver=\"newton-cholesky\"),\n",
    ")\n",
    "model2.fit(diamonds, y)\n",
    "\n",
    "# Performance\n",
    "d2 = model2.score(diamonds, y)\n",
    "print(f\"Percent deviance explained: {d2:.2%}\")\n",
    "\n",
    "# Relative bias\n",
    "bias2 = y.mean() / model2.predict(diamonds).mean() - 1\n",
    "print(f\"Relative bias on USD scale: {bias2:.3%}\")\n",
    "\n",
    "# Fitted coefficients\n",
    "print(\"Intercept\", model2[-1].intercept_)\n",
    "results = pd.DataFrame(\n",
    "    model2[-1].coef_, columns=[\"Estimates\"], index=model2[:-1].get_feature_names_out()\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The coefficients are very similar to the linear regression with log(price) as response. This makes sense as we interpret the coefficients in the same way! The bias is only 0.3%, i.e., much smaller than the 3% of the OLS with log(price) as response. Still, because the log is not the natural link of the Gamma regression, the bias is not exactly 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ml_lecture')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da92bf8b1c4e537ce884cea261fe5226afea19e45e5e1a8d784507cf84f781ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
